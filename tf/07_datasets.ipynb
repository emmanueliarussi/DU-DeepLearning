{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 16:16:18.109460: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries that you may use most times\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Some book keeping    \n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Shift by 1: [[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7], [4, 5, 6, 7, 8], [5, 6, 7, 8, 9], [6, 7, 8, 9], [7, 8, 9], [8, 9], [9]]\n",
      "Shift by 2: [[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7], [4, 5, 6, 7, 8], [5, 6, 7, 8, 9]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-22 19:36:45.738002: W tensorflow/core/framework/dataset.cc:769] Input of Window will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.range(10)\n",
    "print([v.numpy() for v in ds])\n",
    "ds1 = ds.window(5, shift=1)\n",
    "print(\"Shift by 1:\", [[v1.numpy() for v1 in v] for v in ds1])\n",
    "\n",
    "ds1 = ds.window(5, shift=1, drop_remainder=True)\n",
    "print(\"Shift by 2:\", [[v1.numpy() for v1 in v] for v in ds1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64) [0 1 2 3 4]\n",
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int64) [1 2 3 4 5]\n",
      "tf.Tensor([2 3 4 5 6], shape=(5,), dtype=int64) [2 3 4 5 6]\n",
      "tf.Tensor([3 4 5 6 7], shape=(5,), dtype=int64) [3 4 5 6 7]\n",
      "tf.Tensor([4 5 6 7 8], shape=(5,), dtype=int64) [4 5 6 7 8]\n",
      "tf.Tensor([5 6 7 8 9], shape=(5,), dtype=int64) [5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.range(10)\n",
    "ds1 = ds.window(5, shift=1, drop_remainder=True)\n",
    "ds1 = ds1.flat_map(lambda w: w.batch(5))\n",
    "for w in ds1:\n",
    "    print(w, w.numpy())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data for RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset(ds):\n",
    "    for inputs, targets in ds:\n",
    "        print(\"---Batch---\")\n",
    "        print(\"Feature:\", inputs.numpy())\n",
    "        print(\"Label:\", targets.numpy())\n",
    "        print(\"\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(dataset, label_slice, input_sequence_length, output_sequence_length, batch_size):\n",
    "    ds = dataset.window(input_sequence_length + output_sequence_length, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x).batch(input_sequence_length + output_sequence_length)\n",
    "     \n",
    "    def split_feature_label(x):\n",
    "        return x[:input_sequence_length], x[input_sequence_length:,label_slice]\n",
    "     \n",
    "    ds = ds.map(split_feature_label)\n",
    "     \n",
    "    return ds.batch(batch_size)\n",
    " \n",
    "#ds = tf.data.Dataset.from_tensor_slices(simple_data_samples)\n",
    "#ds = timeseries_dataset_from_dataset(ds, slice(3, None, None), input_sequence_length=4, output_sequence_length=2, batch_size=2)\n",
    "#print_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Batch---\n",
      "Feature: [[[  1  10 100  -1  -1]\n",
      "  [  2  20 200  -2  -2]\n",
      "  [  3  30 300  -3  -3]\n",
      "  [  4  40 400  -4  -4]]\n",
      "\n",
      " [[  2  20 200  -2  -2]\n",
      "  [  3  30 300  -3  -3]\n",
      "  [  4  40 400  -4  -4]\n",
      "  [  5  50 500  -5  -5]]]\n",
      "Label: [[[-5 -5]\n",
      "  [-6 -6]]\n",
      "\n",
      " [[-6 -6]\n",
      "  [-7 -7]]]\n",
      "\n",
      "---Batch---\n",
      "Feature: [[[  3  30 300  -3  -3]\n",
      "  [  4  40 400  -4  -4]\n",
      "  [  5  50 500  -5  -5]\n",
      "  [  6  60 600  -6  -6]]\n",
      "\n",
      " [[  4  40 400  -4  -4]\n",
      "  [  5  50 500  -5  -5]\n",
      "  [  6  60 600  -6  -6]\n",
      "  [  7  70 700  -7  -7]]]\n",
      "Label: [[[-7 -7]\n",
      "  [-8 -8]]\n",
      "\n",
      " [[-8 -8]\n",
      "  [-9 -9]]]\n",
      "\n",
      "---Batch---\n",
      "Feature: [[[  5  50 500  -5  -5]\n",
      "  [  6  60 600  -6  -6]\n",
      "  [  7  70 700  -7  -7]\n",
      "  [  8  80 800  -8  -8]]\n",
      "\n",
      " [[  6  60 600  -6  -6]\n",
      "  [  7  70 700  -7  -7]\n",
      "  [  8  80 800  -8  -8]\n",
      "  [  9  90 900  -9  -9]]]\n",
      "Label: [[[ -9  -9]\n",
      "  [-10 -10]]\n",
      "\n",
      " [[-10 -10]\n",
      "  [-11 -11]]]\n",
      "\n",
      "---Batch---\n",
      "Feature: [[[   7   70  700   -7   -7]\n",
      "  [   8   80  800   -8   -8]\n",
      "  [   9   90  900   -9   -9]\n",
      "  [  10  100 1000  -10  -10]]]\n",
      "Label: [[[-11 -11]\n",
      "  [-12 -12]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(values)\n",
    "ds = window(ds, slice(3, 5, None), input_sequence_length=4, output_sequence_length=2, batch_size=2)\n",
    "print_dataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = tf.data.experimental.CsvDataset(\"../data/stockdata.csv\", header=True) #, record_defaults=[5])\n",
    "#ds = ds.map(lambda *items: tf.stack(items))\n",
    "#ds = window(ds, slice(3, None, None), input_sequence_length=4, output_sequence_length=2, batch_size=2)\n",
    "#print_dataset(ds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.30</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.40</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.90</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.10</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420546</th>\n",
       "      <td>2016-12-31 23:20:00</td>\n",
       "      <td>1000.07</td>\n",
       "      <td>-4.05</td>\n",
       "      <td>269.10</td>\n",
       "      <td>-8.13</td>\n",
       "      <td>73.10</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1292.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.52</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420547</th>\n",
       "      <td>2016-12-31 23:30:00</td>\n",
       "      <td>999.93</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>269.81</td>\n",
       "      <td>-8.06</td>\n",
       "      <td>69.71</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1289.44</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.92</td>\n",
       "      <td>234.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420548</th>\n",
       "      <td>2016-12-31 23:40:00</td>\n",
       "      <td>999.82</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>270.01</td>\n",
       "      <td>-8.21</td>\n",
       "      <td>67.91</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1288.39</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.00</td>\n",
       "      <td>215.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420549</th>\n",
       "      <td>2016-12-31 23:50:00</td>\n",
       "      <td>999.81</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>268.94</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>71.80</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1293.56</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.16</td>\n",
       "      <td>225.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420550</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>999.82</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>268.36</td>\n",
       "      <td>-8.42</td>\n",
       "      <td>75.70</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1296.38</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.96</td>\n",
       "      <td>184.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420551 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0      2009-01-01 00:10:00    996.52     -8.02    265.40        -8.90   93.30   \n",
       "1      2009-01-01 00:20:00    996.57     -8.41    265.01        -9.28   93.40   \n",
       "2      2009-01-01 00:30:00    996.53     -8.51    264.91        -9.31   93.90   \n",
       "3      2009-01-01 00:40:00    996.51     -8.31    265.12        -9.07   94.20   \n",
       "4      2009-01-01 00:50:00    996.51     -8.27    265.15        -9.04   94.10   \n",
       "...                    ...       ...       ...       ...          ...     ...   \n",
       "420546 2016-12-31 23:20:00   1000.07     -4.05    269.10        -8.13   73.10   \n",
       "420547 2016-12-31 23:30:00    999.93     -3.35    269.81        -8.06   69.71   \n",
       "420548 2016-12-31 23:40:00    999.82     -3.16    270.01        -8.21   67.91   \n",
       "420549 2016-12-31 23:50:00    999.81     -4.23    268.94        -8.53   71.80   \n",
       "420550 2017-01-01 00:00:00    999.82     -4.82    268.36        -8.42   75.70   \n",
       "\n",
       "        VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "0               3.33          3.11          0.22       1.94             3.12   \n",
       "1               3.23          3.02          0.21       1.89             3.03   \n",
       "2               3.21          3.01          0.20       1.88             3.02   \n",
       "3               3.26          3.07          0.19       1.92             3.08   \n",
       "4               3.27          3.08          0.19       1.92             3.09   \n",
       "...              ...           ...           ...        ...              ...   \n",
       "420546          4.52          3.30          1.22       2.06             3.30   \n",
       "420547          4.77          3.32          1.44       2.07             3.32   \n",
       "420548          4.84          3.28          1.55       2.05             3.28   \n",
       "420549          4.46          3.20          1.26       1.99             3.20   \n",
       "420550          4.27          3.23          1.04       2.01             3.23   \n",
       "\n",
       "        rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0            1307.75      1.03           1.75     152.3  \n",
       "1            1309.80      0.72           1.50     136.1  \n",
       "2            1310.24      0.19           0.63     171.6  \n",
       "3            1309.19      0.34           0.50     198.0  \n",
       "4            1309.00      0.32           0.63     214.3  \n",
       "...              ...       ...            ...       ...  \n",
       "420546       1292.98      0.67           1.52     240.0  \n",
       "420547       1289.44      1.14           1.92     234.3  \n",
       "420548       1288.39      1.08           2.00     215.2  \n",
       "420549       1293.56      1.49           2.16     225.8  \n",
       "420550       1296.38      1.23           1.96     184.9  \n",
       "\n",
       "[420551 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../data/jena_climate_2009_2016.csv.zip'\n",
    "#file = '../data/stockdata.csv'\n",
    "df = pd.read_csv(file)\n",
    "df['Date Time'] = pd.to_datetime( df['Date Time'] )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testvalues():\n",
    "    values = np.array([\n",
    "         [1, 10, 100,  -1, -1],\n",
    "         [2, 20, 200,  -2, -2],\n",
    "         [3, 30, 300,  -3, -3],\n",
    "         [4, 40, 400,  -4, -4],\n",
    "         [5, 50, 500,  -5, -5],\n",
    "         [6, 60, 600,  -6, -6],\n",
    "         [7, 70, 700,  -7, -7],\n",
    "         [8, 80, 800,  -8, -8],\n",
    "         [9, 90, 900,  -9, -9],\n",
    "         [10,100,1000, -10, -10],\n",
    "         [11,110,1100, -11, -11],\n",
    "         [12,120,1200, -12, -12],\n",
    "    ])\n",
    "    return values;\n",
    "\n",
    "def print_test(ds, len=4):\n",
    "    for inputs, targets in ds:\n",
    "        print(inputs.numpy() , targets.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1  10 100  -1  -1]\n",
      " [  2  20 200  -2  -2]\n",
      " [  3  30 300  -3  -3]\n",
      " [  4  40 400  -4  -4]\n",
      " [  5  50 500  -5  -5]] [600 700]\n",
      "[[  2  20 200  -2  -2]\n",
      " [  3  30 300  -3  -3]\n",
      " [  4  40 400  -4  -4]\n",
      " [  5  50 500  -5  -5]\n",
      " [  6  60 600  -6  -6]] [700 800]\n",
      "[[  3  30 300  -3  -3]\n",
      " [  4  40 400  -4  -4]\n",
      " [  5  50 500  -5  -5]\n",
      " [  6  60 600  -6  -6]\n",
      " [  7  70 700  -7  -7]] [800 900]\n",
      "[[  4  40 400  -4  -4]\n",
      " [  5  50 500  -5  -5]\n",
      " [  6  60 600  -6  -6]\n",
      " [  7  70 700  -7  -7]\n",
      " [  8  80 800  -8  -8]] [ 900 1000]\n",
      "[[  5  50 500  -5  -5]\n",
      " [  6  60 600  -6  -6]\n",
      " [  7  70 700  -7  -7]\n",
      " [  8  80 800  -8  -8]\n",
      " [  9  90 900  -9  -9]] [1000 1100]\n",
      "[[   6   60  600   -6   -6]\n",
      " [   7   70  700   -7   -7]\n",
      " [   8   80  800   -8   -8]\n",
      " [   9   90  900   -9   -9]\n",
      " [  10  100 1000  -10  -10]] [1100 1200]\n"
     ]
    }
   ],
   "source": [
    "window_len = 5\n",
    "fcast_len  = 2\n",
    "batch_size = 2\n",
    "\n",
    "#values = df.values[:, 1:5]\n",
    "values = testvalues()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "dataset = dataset.window(window_len + fcast_len, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda x: x).batch(window_len + fcast_len)\n",
    "\n",
    "def split_feature_label(x):\n",
    "    return x[:window_len], x[window_len:,fcast_len]\n",
    "     \n",
    "dataset = dataset.map(split_feature_label)\n",
    "dataset.batch(batch_size)\n",
    "print_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1,  10, 100,  -1,  -1],\n",
       "        [  2,  20, 200,  -2,  -2],\n",
       "        [  3,  30, 300,  -3,  -3],\n",
       "        [  4,  40, 400,  -4,  -4],\n",
       "        [  5,  50, 500,  -5,  -5]]),\n",
       " array([[600,  -6],\n",
       "        [700,  -7]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv=np.array([\n",
    " [ 1 , 1 , 1 ,-1 , -1],\n",
    " [ 2 , 2 , 2 ,-2 , -2],\n",
    " [ 3 , 3 , 3 ,-3 , -3],\n",
    " [ 4 , 4 , 4 ,-4 , -4],\n",
    " [ 5 , 5 , 5 ,-5 , -5],\n",
    " [ 6 , 6 , 6 ,-6 , -6],\n",
    " [ 7 , 7 , 7 ,-7 , -7]])\n",
    "\n",
    "vv = values\n",
    "vv[:5], vv[5:7,2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  1  1 -1 -1]\n",
      " [ 2  2  2 -2 -2]\n",
      " [ 3  3  3 -3 -3]\n",
      " [ 4  4  4 -4 -4]\n",
      " [ 5  5  5 -5 -5]\n",
      " [ 6  6  6 -6 -6]\n",
      " [ 7  7  7 -7 -7]], shape=(7, 5), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 2  2  2 -2 -2]\n",
      " [ 3  3  3 -3 -3]\n",
      " [ 4  4  4 -4 -4]\n",
      " [ 5  5  5 -5 -5]\n",
      " [ 6  6  6 -6 -6]\n",
      " [ 7  7  7 -7 -7]\n",
      " [ 8  8  8 -8 -8]], shape=(7, 5), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[ 3  3  3 -3 -3]\n",
      " [ 4  4  4 -4 -4]\n",
      " [ 5  5  5 -5 -5]\n",
      " [ 6  6  6 -6 -6]\n",
      " [ 7  7  7 -7 -7]\n",
      " [ 8  8  8 -8 -8]\n",
      " [ 9  9  9 -9 -9]], shape=(7, 5), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[  4   4   4  -4  -4]\n",
      " [  5   5   5  -5  -5]\n",
      " [  6   6   6  -6  -6]\n",
      " [  7   7   7  -7  -7]\n",
      " [  8   8   8  -8  -8]\n",
      " [  9   9   9  -9  -9]\n",
      " [ 10  10  10 -10 -10]], shape=(7, 5), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[  5   5   5  -5  -5]\n",
      " [  6   6   6  -6  -6]\n",
      " [  7   7   7  -7  -7]\n",
      " [  8   8   8  -8  -8]\n",
      " [  9   9   9  -9  -9]\n",
      " [ 10  10  10 -10 -10]\n",
      " [ 11  11  11 -11 -11]], shape=(7, 5), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[  6   6   6  -6  -6]\n",
      " [  7   7   7  -7  -7]\n",
      " [  8   8   8  -8  -8]\n",
      " [  9   9   9  -9  -9]\n",
      " [ 10  10  10 -10 -10]\n",
      " [ 11  11  11 -11 -11]\n",
      " [ 12  12  12 -12 -12]], shape=(7, 5), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "values = testvalues()\n",
    "dataset = tf.data.Dataset.from_tensor_slices(values)\n",
    "dataset = dataset.window(window_len + fcast_len, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda x: x).batch(window_len + fcast_len)\n",
    "for w in (dataset):\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series generator Example:\n",
    "\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "dftt = pd.read_csv(\"\");\n",
    "gen = TimeseriesGenerator(dftt.values,dftt.values, length =window_len, batch_size = batch_size)\n",
    "print(\"========================\")\n",
    "for g in gen:\n",
    "    print(g[1])\n",
    "    break;\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
