{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 02:20:23.506077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries that you may use most times\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mpl.rcParams['figure.figsize'] = (16, 5)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "# -------------------------------------------------------------------------\n",
    "# 1. Some book keeping    \n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "#See also: https://mobiarch.wordpress.com/2020/11/13/preparing-time-series-data-for-rnn-in-tensorflow/\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCSV(file = '../data/jena_climate_2009_2016.csv.zip', nrows=1024*1024):\n",
    "    df = pd.read_csv(file, nrows = nrows)\n",
    "    return df\n",
    "\n",
    "def getTest():\n",
    "    values = np.array([\n",
    "         [1, 10, 100,  -1, -1],\n",
    "         [2, 20, 200,  -2, -2],\n",
    "         [3, 30, 300,  -3, -3],\n",
    "         [4, 40, 400,  -4, -4],\n",
    "         [5, 50, 500,  -5, -5],\n",
    "         [6, 60, 600,  -6, -6],\n",
    "         [7, 70, 700,  -7, -7],\n",
    "         [8, 80, 800,  -8, -8],\n",
    "         [9, 90, 900,  -9, -9],\n",
    "         [10,100,1000, -10, -10],\n",
    "         [11,110,1100, -11, -11],\n",
    "         [12,120,1200, -12, -12],\n",
    "    ])\n",
    "    return values;\n",
    "\n",
    "def printDS(ds, len=4):\n",
    "    i = 0\n",
    "    for inputs, targets in ds:\n",
    "        print(inputs.numpy() , targets.numpy())\n",
    "        i += 1\n",
    "        if ( i >= len):\n",
    "            break;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1  10 100  -1  -1]\n",
      "  [  2  20 200  -2  -2]\n",
      "  [  3  30 300  -3  -3]\n",
      "  [  4  40 400  -4  -4]\n",
      "  [  5  50 500  -5  -5]]\n",
      "\n",
      " [[  2  20 200  -2  -2]\n",
      "  [  3  30 300  -3  -3]\n",
      "  [  4  40 400  -4  -4]\n",
      "  [  5  50 500  -5  -5]\n",
      "  [  6  60 600  -6  -6]]] [[[  6  60 600]\n",
      "  [  7  70 700]]\n",
      "\n",
      " [[  7  70 700]\n",
      "  [  8  80 800]]]\n"
     ]
    }
   ],
   "source": [
    "values = getTest()\n",
    "window_len = 5\n",
    "output_len = 2\n",
    "batch_size = 2\n",
    "\n",
    "def tsdata(ds, label_slice, window_len, output_len=1, batch_size=1):\n",
    "    ds = ds.window(window_len + output_len, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x).batch(window_len + output_len)\n",
    "     \n",
    "    def feature_label(x):\n",
    "        return x[:window_len], x[window_len:,label_slice]\n",
    "\n",
    "    ds = ds.map(feature_label)\n",
    "\n",
    "    return ds.batch(batch_size)\n",
    " \n",
    "ds = tf.data.Dataset.from_tensor_slices(values)\n",
    "\n",
    "#ds = tf.data.experimental.CsvDataset(\"../stock_data.csv\", header=True, record_defaults=[int()]*15)\n",
    "#ds = ds.map(lambda *items: tf.stack(items))\n",
    "\n",
    "ds = tsdata(ds, slice(0,3), window_len=window_len, output_len=output_len, batch_size=batch_size)\n",
    "printDS(ds, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "beginner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dff0aaeeb8ee9738611fdcb903e0426fbcf38bc2d039ac205716a81cc1909598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
