{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XVhK72Pu1cJL"
   },
   "source": [
    "#### Anomaly Detection - Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T02:53:20.699018Z",
     "iopub.status.busy": "2022-12-14T02:53:20.698277Z",
     "iopub.status.idle": "2022-12-14T02:53:23.285398Z",
     "shell.execute_reply": "2022-12-14T02:53:23.284632Z"
    },
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Dropout, SimpleRNN, Dense, LSTM, RepeatVector, Input, TimeDistributed, concatenate\n",
    "from keras import regularizers\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import IPython, IPython.display, os, datetime\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (14, 4)\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "\n",
    "print(f\"Tensorflow Version {tf.__version__}, Keras Vesion: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ts_utils\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# STEP 1: = >Lets just read the first few columns for testing\n",
    "df = pd.read_csv(\"../data/processminer-rare-event-mts.csv.zip\", sep=';', usecols=range(59))\n",
    "split = int (.8 * len(df) )\n",
    "df_scaled_trn = df [df.columns[2:] ][0:split ]\n",
    "df_scaled_tst = df [df.columns[2:] ][split: ]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled_trn = pd.DataFrame(scaler.fit_transform(df_scaled_trn), columns=df_scaled_trn.columns)\n",
    "df_scaled_tst = pd.DataFrame(scaler.transform(df_scaled_tst), columns=df_scaled_tst.columns)\n",
    "\n",
    "\n",
    "#  STEP 2: => Create window\n",
    "\n",
    "input_slice  = slice(0, len(df_scaled_trn.columns) )\n",
    "label_slice  = input_slice\n",
    "window_len   = 5\n",
    "ouput_len    = 1\n",
    "batch_size   = 128\n",
    "\n",
    "inp_feat_len   = input_slice.stop - (input_slice.start or 0)\n",
    "ouput_feat_len = label_slice.stop - (label_slice.start or 0)\n",
    "\n",
    "ds_trn     = tf.data.Dataset.from_tensor_slices(df_scaled_trn[df_scaled_trn.columns[input_slice]])\n",
    "ds_tst     = tf.data.Dataset.from_tensor_slices(df_scaled_tst[df_scaled_trn.columns[input_slice]])\n",
    "window_trn = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=batch_size, for_aencoder=1)\n",
    "window_tst = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=batch_size, for_aencoder=1)\n",
    "\n",
    "window_trn100 = ts_utils.window(ds_trn, window_len, ouput_len, label_slice, batch_size=100000, for_aencoder=1)\n",
    "window_tst100 = ts_utils.window(ds_tst, window_len, ouput_len, label_slice, batch_size=100000, for_aencoder=1)\n",
    "\n",
    "display( pd.concat([df, df_scaled_trn], axis=1))\n",
    "#for w in window_trn.take(1): print(f'{w[0]} \\n\\n {w[1]}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "lstm_ae1 = Sequential(name=\"Simple_LSTM_AE\")\n",
    "# Encoder\n",
    "lstm_ae1.add(LSTM(32, activation='relu', input_shape=(window_len, inp_feat_len), return_sequences=True))\n",
    "lstm_ae1.add(LSTM(16, activation='relu', return_sequences=False))\n",
    "lstm_ae1.add(RepeatVector(window_len))\n",
    "# Decoder\n",
    "lstm_ae1.add(LSTM(16, activation='relu', return_sequences=True))\n",
    "lstm_ae1.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "lstm_ae1.add(TimeDistributed(Dense(inp_feat_len)))\n",
    "\n",
    "lstm_ae1.summary()\n",
    "\n",
    "plot_model(lstm_ae1, show_shapes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 128\n",
    "\n",
    "# Create Autoencoder Layer\n",
    "input_layer = Input(shape=(window_len, inp_feat_len), dtype='float32', name='input')\n",
    "memory_layer = LSTM(dim, return_sequences=True)(input_layer)\n",
    "memory_layer = LSTM (int(dim//2), return_sequences=False)(memory_layer)\n",
    "repeated_lyr = RepeatVector(window_len)(memory_layer)\n",
    "memory_layer = LSTM (int(dim//2), return_sequences=True)(repeated_lyr)\n",
    "memory_layer = LSTM (dim,  return_sequences=True)(memory_layer)\n",
    "decoded_inputs = TimeDistributed(Dense(units=inp_feat_len, activation='linear'))( memory_layer)\n",
    "\n",
    "dropout_input = Dropout(0.2)(input_layer)\n",
    "concat_layer = concatenate([dropout_input, decoded_inputs])\n",
    "memory_layer = LSTM(units=dim, \n",
    "                    kernel_regularizer = regularizers.l1_l2(l1= .1, l2= .1), \n",
    "                    recurrent_regularizer = regularizers.l1_l2(l1= .1, l2= .1), \n",
    "                    return_sequences=False)(concat_layer)\n",
    "preds = Dense(units=inp_feat_len, activation='linear')(memory_layer)\n",
    "\n",
    "umodel = Model(input_layer, preds)\n",
    "#umodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_ae1\n",
    "#model = umodel\n",
    "history = ts_utils.compile_fit(model, window_trn, window_tst= window_trn, patience=30, epochs=50)\n",
    "\n",
    "IPython.display.clear_output()\n",
    "\n",
    "for l in history.history:\n",
    "    plt.plot(history.history[l], label=f\"{l}\")\n",
    "plt.title(\"History of Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly - precision/Recall etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_ae1\n",
    "\n",
    "for w in window_trn100:\n",
    "    p = model.predict(w[0])\n",
    "    \n",
    "e = np.mean((p - w[0])**2, axis=1)\n",
    "m = np.sum(e, axis=1)\n",
    "\n",
    "y= df.y[0:len(e)]\n",
    "yy = [np.nan if j<1 else m[i] for i,j in enumerate(y)]\n",
    "\n",
    "plt.plot(range(len(e)), m, alpha=0.2, c='orange', marker='o', label=\"score\", linestyle='', markersize=.5);\n",
    "plt.plot(yy, marker='x', c=\"red\" , linestyle=\"\", markersize=3)\n",
    "\n",
    "plt.title(f\"Reconstruction Error: #Anomalies: {sum(y)}\")\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in window_tst100:\n",
    "    p = model.predict(w[0])\n",
    "    \n",
    "et = np.mean((p - w[0])**2, axis=1)\n",
    "mt = np.sum(et, axis=1)\n",
    "\n",
    "yt= df.y[0:len(et)]\n",
    "yy = [np.nan if j<1 else mt[i] for i,j in enumerate(yt)]\n",
    "\n",
    "plt.plot(range(len(et)), mt, alpha=0.2, c='orange', marker='o', label=\"score\", linestyle='', markersize=.5);\n",
    "plt.plot(yy, marker='x', c=\"red\" , linestyle=\"\", markersize=3)\n",
    "\n",
    "plt.title(f\"Reconstruction Error Test: #Anomalies: {sum(yt)}\")\n",
    "plt.ylim(0,7)\n",
    "plt.legend();\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Precision Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "\n",
    "\n",
    "prec, recall, thr = precision_recall_curve(y, m)\n",
    "plt.plot(thr, prec[1:],   label=\"Precision\", marker='o', linewidth=1, markersize=1)\n",
    "plt.plot(thr, recall[1:], label=\"Recall\",    marker='x', linewidth=1, markersize=1)\n",
    "plt.title('PR Curve')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Precision/Recall')\n",
    "plt.legend()\n",
    "#plt.xlim(2,2.5)\n",
    "#plt.ylim(0,.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.8\n",
    "yhat = [1 if e > THRESHOLD else 0 for e in m]\n",
    "cm = confusion_matrix(y, yhat)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"True\", \"False\"])\n",
    "\n",
    "cost_fp= 1      # Cost of False Positive\n",
    "cost_fn= 100    # Cost of False Negative\n",
    "\n",
    "tcost = cm[0,1] * cost_fp +  cm[1,0] * cost_fn\n",
    "\n",
    "disp.plot()\n",
    "plt.title(f\"Total cost ${tcost}\")\n",
    "plt.grid(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "time_series.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "dff0aaeeb8ee9738611fdcb903e0426fbcf38bc2d039ac205716a81cc1909598"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
