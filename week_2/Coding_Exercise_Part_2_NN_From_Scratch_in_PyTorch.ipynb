{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdphshS5I3ra"
   },
   "source": [
    "# Coding Exercise Part 2: NN from Scratch in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epr7o9LkIwS6"
   },
   "source": [
    "### Objective\n",
    "* Code a \"vanilla\" feedforward neural network from the scratch in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WTJ9L3ZIpXl",
    "outputId": "d3984260-87c7-498e-df42-f121fa2485c6"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fix random seed: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "torch.manual_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtpE0pg9ZIBc"
   },
   "source": [
    "### 2. Implement Neural Network class\n",
    "\n",
    "In this exercise, you will implement a simple feed-forward neural network using PyTorch for binary classification tasks.\n",
    "\n",
    "**Objectives:** \n",
    "* Implement the initialization method for the neural network.\n",
    "* Implement the forward propagation step.\n",
    "* Implement the training loop, including the forward pass, loss computation, and parameter updates.\n",
    "\n",
    "**Background:**\n",
    "\n",
    "**Feed-forward Neural Network:** This is a type of artificial neural network where the connections between the nodes do not form a cycle. In this exercise, the neural network will have an input layer, one hidden layer, and an output layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GssZFh7nI6tL"
   },
   "outputs": [],
   "source": [
    "# Define the Neural Network using PyTorch\n",
    "class PyTorchNeuralNetwork(nn.Module):    \n",
    "    # Init\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PyTorchNeuralNetwork, self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the neural network with the given sizes.\n",
    "\n",
    "        Args:\n",
    "        - input_size: Integer, the number of input features.\n",
    "        - hidden_size: Integer, the number of neurons in the hidden layer.\n",
    "        - output_size: Integer, the number of neurons in the output layer (usually 1 for binary classification).\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        \n",
    "        # First fully connected layer (input to hidden)\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "        self.fc1 = #...\n",
    "\n",
    "        # Second fully connected layer (hidden to output)\n",
    "        self.fc2 = #...\n",
    "\n",
    "        # Sigmoid activation function for the output layer\n",
    "        self.sigmoid = #...\n",
    "\n",
    "    # Perform forward propagation step\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform the forward propagation step.\n",
    "\n",
    "        Args:\n",
    "        - x: A PyTorch tensor of shape (batch_size, input_size).\n",
    "\n",
    "        Returns:\n",
    "        - x: A PyTorch tensor of shape (batch_size, output_size) representing the model's predictions.\n",
    "        \"\"\"\n",
    "        # Your code here\n",
    "        \n",
    "    # Trains the neural network using the specified data (X_train) and labels (Y_train)\n",
    "    def train(self, X_train, Y_train, learning_rate=0.01, epochs=5000):\n",
    "        \"\"\"\n",
    "        Train the neural network using the provided training data.\n",
    "\n",
    "        Args:\n",
    "        - X_train: A PyTorch tensor of shape (n_samples, input_size) containing the training data.\n",
    "        - Y_train: A PyTorch tensor of shape (n_samples, output_size) containing the true labels.\n",
    "        - learning_rate: Learning rate for the optimizer.\n",
    "        - epochs: Number of epochs to train the model.\n",
    "        \"\"\"\n",
    "        # Use Binary Cross Entropy Loss for binary classification\n",
    "        criterion = nn.BCELoss()\n",
    "\n",
    "        # Use the Adam optimizer for parameter updates\n",
    "        optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        # List to store loss values for each epoch\n",
    "        self.losses = []\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # Your code here\n",
    "            \n",
    "            # Forward pass: Compute predicted y by passing x to the model\n",
    "            outputs = #...\n",
    "\n",
    "            # Compute the loss\n",
    "            loss    = #...\n",
    "\n",
    "            # Zero gradients, backward pass, optimizer step\n",
    "            optimizer.zero_grad()  # Zero out any cached gradients\n",
    "            loss.backward()        # Compute gradient of the loss with respect to model parameters\n",
    "            optimizer.step()       # Update model parameters\n",
    "\n",
    "            # Store the loss value\n",
    "            self.losses.append(loss.item())\n",
    "\n",
    "            # Print the loss every 100 epochs\n",
    "            if (epoch+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the outputs for the given inputs X.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():  # No need to compute gradients during prediction\n",
    "            outputs = self.forward(X)\n",
    "            return (outputs > 0.5).int() # Convert probabilities to binary outputs\n",
    "\n",
    "    def plot_loss(self):\n",
    "        # Plotting the loss curve\n",
    "        plt.plot(self.losses)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss (BCE)\")\n",
    "        plt.title(\"Loss curve\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM2whZkSLFGH"
   },
   "source": [
    "### 3. Load dataset\n",
    "We will work with the Habermanâ€™s Survival Dataset. The dataset contains cases from a study that was conducted between 1958 and 1970 at the University of Chicago's Billings Hospital on the survival of patients who had undergone surgery for breast cancer. There are 306 items (patients). There are three predictor variables (age, year of operation, number of detected nodes). The variable to predict is encoded as 0 (survived) or 1 (died). See [\n",
    "Haberman's Survival Dataset](https://archive.ics.uci.edu/dataset/43/haberman+s+survival)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNwOa5U1K9oU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/emmanueliarussi/DU-DeepLearning/main/week_2/haberman_data/haberman.data'\n",
    "headers =  ['age', 'year','nodes','y']\n",
    "haberman_df  = pd.read_csv(url, sep=',', names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-OLAZOUBLId1",
    "outputId": "a70b7b77-7972-45ba-d4b5-7183ac861495"
   },
   "outputs": [],
   "source": [
    "haberman_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcJOZp0JLK5T"
   },
   "outputs": [],
   "source": [
    "# Convert pandas dataframe into numpy arrays\n",
    "x       = haberman_df.drop(columns=['y']).values[1:]\n",
    "y_label = haberman_df['y'].values[1:].reshape(x.shape[0], 1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-sK-UMXLMrK"
   },
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y_label, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anXJ6jF9LO8T",
    "outputId": "ebbd0f74-5024-4313-9b00-744ef8d87a51"
   },
   "outputs": [],
   "source": [
    "# Standardize the dataset\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(xtrain)\n",
    "xtrain = sc.transform(xtrain)\n",
    "xtest  = sc.transform(xtest)\n",
    "\n",
    "print(\"Shape of train set is {}\".format(xtrain.shape))\n",
    "print(\"Shape of test set is {}\".format(xtest.shape))\n",
    "print(\"Shape of train label is {}\".format(ytrain.shape))\n",
    "print(\"Shape of test labels is {}\".format(ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5I57GAsLYtN"
   },
   "outputs": [],
   "source": [
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train = torch.FloatTensor(xtrain)\n",
    "Y_train = torch.FloatTensor(ytrain)\n",
    "X_test = torch.FloatTensor(xtest)\n",
    "Y_test = torch.FloatTensor(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "U89cCftPK43P",
    "outputId": "aa17d0e0-1188-4b32-dd12-73b3054b4ebe"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = PyTorchNeuralNetwork(input_size=3, hidden_size=5, output_size=1)\n",
    "\n",
    "# Train the model\n",
    "model.train(X_train, Y_train, epochs=5000, learning_rate=0.01)\n",
    "\n",
    "# Plot the loss curve\n",
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BQRRzq8Mbbh"
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    # Computes the accuracy between the predicted labels and the truth labels\n",
    "    acc = sum(y == y_hat) / len(y)  # fraction of predictions our model got right\n",
    "    return acc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyfNZYmJLcah",
    "outputId": "0437116f-6450-43e4-aaaa-f33b883fa2f2"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy is {0:.2f}\".format(accuracy(Y_train, train_pred)))\n",
    "print(\"Test accuracy is {0:.2f}\".format(accuracy(Y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jZo150raBsA"
   },
   "source": [
    "### 4. Visualizing Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_nCdc3YCaX2-",
    "outputId": "0f602716-459f-41b7-aa32-4e0e6aa18925"
   },
   "outputs": [],
   "source": [
    "# Repository: https://github.com/szagoruyko/pytorchviz\n",
    "!pip install torchviz\n",
    "\n",
    "import torchviz\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "OSp6D6wWaa1k",
    "outputId": "013f1998-734b-472f-aa98-481df99f45ab"
   },
   "outputs": [],
   "source": [
    "# Create a dummy input that matches the dimensionality of the input\n",
    "dummy_input = torch.FloatTensor(1,3)\n",
    "\n",
    "# Pass the dummy input through the model to get the output\n",
    "output = model(dummy_input)\n",
    "\n",
    "# Visualize the computation graph\n",
    "make_dot(output, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LNwi4cXcKCh"
   },
   "source": [
    "See more in this [PyTorchViz Gallery](https://colab.research.google.com/github/szagoruyko/pytorchviz/blob/master/examples.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C05yMwYycYuY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
